{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication from Foundations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we go along through this version of Part II of the fast.ai Deep Learning course, we'll be recreating from scratch much of the source code found in both the [fastai](https://github.com/fastai/fastai) and [PyTorch](https://pytorch.org/docs/stable/index.html) libraries.\n",
    "\n",
    "And we'll be doing so using only Jupyter Notebooks. In order to make this work, as we create new notebooks in each new lesson we'll need to be able to import functions and classes written in preceding notebooks. \n",
    "\n",
    "So let's first verify that we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exports.nb_00 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a general method to use to test whether two variables contain identical values. Then we ascertain that we successfully imported from the notebook `nb_00.ipynp` that's in the `exports` folder.\n",
    "\n",
    "This notebook contains one variable, `TEST`, which is defined as the string `\"test\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import operator\n",
    "\n",
    "def test(a,b,cmp,cname=None):\n",
    "    if cname is None: cname=cmp.__name__\n",
    "    assert cmp(a,b),f'{cname}:\\n{a}\\n{b}'\n",
    "    \n",
    "def test_eq(a,b): test(a,b,operator.eq, '==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TEST,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the MNIST Dataset\n",
    "\n",
    "We'll be using [MNIST](https://en.wikipedia.org/wiki/MNIST_database) in this notebook to demonstrate that our re-creations of parts of fastai and PyTorch are working like they're supposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "MNIST_URL = 'http://deeplearning.net/data/mnist/mnist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/.fastai/data/mnist.pkl.gz')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = datasets.download_data(MNIST_URL, ext='.gz'); path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " torch.Size([50000, 784]),\n",
       " tensor([5, 0, 4,  ..., 8, 4, 8]),\n",
       " torch.Size([50000]),\n",
       " tensor(0),\n",
       " tensor(9))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train, x_valid, y_valid))\n",
    "n,c = x_train.shape\n",
    "x_train, x_train.shape, y_train, y_train.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x_train.shape[0]==y_train.shape[0]==50000\n",
    "test_eq(x_train.shape[1],28*28)\n",
    "test_eq(y_train.min(),0)\n",
    "test_eq(y_train.max(),9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell matplotlib to display images using a gray colormap\n",
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.view(28,28).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.view((28,28)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Python Model\n",
    "\n",
    "Shortly, we will create a neural network that will learn to classify the handwriting images of digits that are in the MNIST dataset.\n",
    "\n",
    "Let's start by initiating the weights and biases of our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(784,10)/math.sqrt(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "A big part of training our model will involve matrix multiplication. PyTorch automatically takes care of this for us. But since our goal here is to build up the code necessary to train neural networks from scratch, let's first see exactly how matrix multiplication works. \n",
    "\n",
    "Then we'll optimize our code to make it as fast as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix multiplication using for-loops\n",
    "\n",
    "We're going to discover, step-by-step, how to implement a speed-optimized matrix multiplication method. Let's work our way there by starting off with the a relatively computationally inefficient, but perhaps more intuitive approach of using for-loops.\n",
    "\n",
    "http://matrixmultiplication.xyz/ offers a great animation that visualizes each step of a matrix multiplication.\n",
    "\n",
    "<img src= 'images/mat-mul.png' width='300'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape # shape is (num rows, num cols)\n",
    "    br,bc = b.shape\n",
    "    assert ac==br # num cols in left matrix must equal num rows in right matrix\n",
    "    c = torch.zeros(ar,bc) # shape of the output product\n",
    "    for i in range(ar): # for each row in left matrix\n",
    "        for j in range(bc): # for each col in right matrix\n",
    "            for k in range(ac): # for each col in left matrix, or for each row in right matrix (br)\n",
    "                c[i,j] += a[i,k] * b[k,j]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = x_valid[:5]\n",
    "m2 = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape,m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 766 ms, sys: 0 ns, total: 766 ms\n",
      "Wall time: 766 ms\n"
     ]
    }
   ],
   "source": [
    "%time t1=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using our above for-loop method to compute the matrix product of our network's initial weights with the first five inputs from the validation set, we can see that it takes `766 ms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that our training set has not five, but fifty-thousand items, it's not difficult to imagine that training neural networks would be nigh impossible if the best way we had for performing matrix multiplication was using for-loops.\n",
    "\n",
    "Thankfully, there are better ways!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Element-wise operations\n",
    "\n",
    "The operators +, -, \\*, /, <, >, == are usually element-wise.\n",
    "\n",
    "Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tensor([10., 6, -4])\n",
    "b = tensor([2., 8, 7])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 14.,  3.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a < b).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tensor([[1., 2, 3], [4, 5, 6], [7, 8, 9]]); m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final example will calculate the Frobenius, or $L^{2}$ norm, which is often used to provide regularization when training neural networks:\n",
    "\n",
    "$\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.8819)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m*m).sum().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, it's often easier to understand a math formula by seeing how it's implemented in code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Element-wise matmul\n",
    "\n",
    "We can improve our previous matmul method by replacing the last for-loop with a set of element-wise operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape\n",
    "    br,bc = b.shape\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar,bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            # element-wise multiply each row in the left matrix \n",
    "            # by a given row from the right matrix, and sum\n",
    "            c[i,j] = (a[i,:] * b[:,j]).sum()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938 µs ± 16.2 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816.6311300639659"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "766*1000/938"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about an eight hundred fold improvement over our pure Python implementation that used three for-loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that the element-wise modification we made to our matmul method still results in a similar-enough result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
    "def test_near(a,b): test(a, b, near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1, matmul(m1,m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "**Broadcasting** is a technique used for making the shapes of two tensors compatible, so that arithmetic operations may be performed between the two tensors.\n",
    "\n",
    "We often speak of array operations being *vectorized*. Broadcasting is what makes this possible -- it enables looping to occur in C instead of in Python, and does not make needless copies of data. The actual term *broadcasting* was first [used by NumPy](https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html).\n",
    "\n",
    "As long as certain constraints are satisfied, the shape of smaller tensor is expanded to the size that would make it possible to efficiently perform an arithmetic operation between it and the larger tensor.\n",
    "\n",
    "One additional benefit of broadcasting is that it lets the programmer specify the same behavior in fewer lines of code, as we will see below when we incorporate it as part of a revised matmul function.\n",
    "\n",
    "Less code means a smaller chance that bugs will be inadvertently introduced during development.\n",
    "\n",
    "Below are several different kinds of situations that exemplify how broadcasting is applied:\n",
    "\n",
    "#### Broadcasting with a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  6., -4.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to broadcasting, the above operation is completed as if each element in tensor `a` is being compared element-wise to `tensor([0, 0, 0])`. \n",
    "\n",
    "Additionally, memory is conserved because the only thing still stored in memory is `0`, as opposed to a tensor that contains one row with three elements. For each element-wise comparison, the C code pretends that this `0` value is the 0th, 1st, and finally 2nd indexed element of a tensor with one row, three elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.,  7., -3.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.],\n",
       "        [14., 16., 18.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting a vector to a matrix\n",
    "\n",
    "Similarly to how we made a scalar behave as if it were a larger matrix full of identical values of that same scalar, we can also take a vector and broadcast its shape so that element-wise operations can be performed on it as if it had a higher dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tensor([10.,20,30]); c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c + m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vector `c` is indeed still stored in memory as a vector, but its elements have been added to the corresponding three elements in each row in the matrix `m`. \n",
    "\n",
    "More specifically, the rows of vector `c` have a *stride* of zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = c.expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10.0\n",
       " 20.0\n",
       " 30.0\n",
       "[torch.FloatStorage of size 3]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.stride(), t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some indexing tips and tricks\n",
    "\n",
    "To increase an array's dimension:\n",
    "\n",
    "* Index with the special value **`None`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, c[None,:].shape, c[:,None].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `unsqueeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, c.unsqueeze(0).shape, c.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trailing `:`'s can always be skipped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None].shape, c[None,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'...'` means *\"include all preceding dimensions\"*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[...,None].shape, c[:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10.],\n",
       "        [20., 20., 20.],\n",
       "        [30., 30., 30.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[...,None].expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 12., 13.],\n",
       "        [24., 25., 26.],\n",
       "        [37., 38., 39.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + c[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None].expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + c[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10.],\n",
       "         [20.],\n",
       "         [30.]]), tensor([[10., 20., 30.]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[...,None], c[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw just now, `c[...,None]` and `c[None]` have different shapes. The former is one column and the latter is one row. When each is broadcast out to the shape of `m`, `c[...,None]`'s one column are duplicated such that its rows are as long as those of `m`. And `c[None]`'s one row is duplicated, such that it now has as many columns as `m`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting Rules\n",
    "\n",
    "When operating on two arrays, NumPy/PyTorch compares their shapes *element-wise*. \n",
    "\n",
    "It starts with **trailing dimensions**, and works its way forward. Two dimensions are deemed **compatible** when at least one of the following two conditions are met:\n",
    "\n",
    "* They are equal.\n",
    "* One of the dimensions is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that arrays *do not* need to have the same number of dimensions. If, for example, you have a `(256,256,3)` shaped array of RGB color values and you want to scale each color/channel of an image by a different value, it is sufficient to just multiply the image by a 1-D array with three values.\n",
    "\n",
    "If you line up the sizes of the trailing axes according to the broadcasting rules, you can observe that they are compatible:\n",
    "\n",
    "```\n",
    "Image  (3d array): 256 x 256 x 3\n",
    "Scale  (1d array):             3\n",
    "Result (3d array): 256 x 256 x 3\n",
    "```\n",
    "\n",
    "NumPy documentation shows [several examples](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html#general-broadcasting-rules) of what dimensions can and can't be broadcast together.\n",
    "\n",
    "For example, in \n",
    "\n",
    "```\n",
    "A      (2d array):      2 x 1\n",
    "B      (3d array):  8 x 4 x 3 \n",
    "```\n",
    "A and B cannot be broadcast together because the respective sizes of their second-to-last dimension don't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [20.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100., 200., 300.],\n",
       "        [200., 400., 600.],\n",
       "        [300., 600., 900.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:] * c[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, `c[None,:]` can be broadcast to the shape of `c[:,None]` since the size of it's trailing dimension (3) is the same as the size of `c[:,None]`'s trailing dimension, even though the former's trailing dimension happens to be a row, while that of the latter happens to be a columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matmul with broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further speed up our matrix multiplication method by taking advantage of broadcasting. We go row-by-row through the left-hand matrix, broadcasting each row of the left-hand matrix out to the size of the right-hand matrix, performing an element-wise multiplication between the two matrices, and then summing up this result across its rows. The resulting vector becomes one row in the final product `c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape\n",
    "    br,bc = b.shape\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        # c[i,j] = (a[i,:] * b[:,j]).sum() # previous approach\n",
    "        c[i] = (a[i,:].unsqueeze(-1) * b).sum(dim=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258 µs ± 85.4 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.635658914728682"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "938/258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is under four times faster than our previous best attempt above. Let's make sure the this latest matmul method still returns the correct answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1, matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, notice how we unsqueezed each row of `a` before then broadcasting it so that we could perform an element-wise multiplacation with `b`. Here's what unsqueeze does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0,:].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above unsqueeze takes a given row from `m` and turns it into one column, filling that column with a row for each element that was originally in the given row in `m`. The same thing was done for each row in the matrix `a` in our latest matmul method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einstein Summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Einstein summation](https://docs.scipy.org/doc/numpy/reference/generated/numpy.einsum.html) offers a very concise description for combining products and sums. It is comma-separated string of subscript labels that can be used to describe, and then compute, a wide variety of multi-dimensional array operations. \n",
    "\n",
    "For example, the following notation to describes matrix multiplication:\n",
    "```\n",
    "'ij,jk'\n",
    "```\n",
    "\n",
    "Each letter refers to a dimension and each matrix is separated by a comma. The left-hand matrix has `i` rows and `j` columns. While the right-hand matrix has `j` rows (which we would expect to be the case for two matrices we will multiply together) and `k` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b): return torch.einsum('ij,jk', a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.3 µs ± 7.74 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1, matmul(m1,m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.4019851116625315"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "258/40.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using einstein summation allows us to perform matmul six times faster than the time it took using broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastest: matrix multiplication using PyTorch\n",
    "\n",
    "Below, we'll see that PyTorch's matmul operation is the fastest of all the available approaches. PyTorch goes one step further and kicks the matmul operation out to the basic linear algebra subprograms (BLAS) library tailored to Nvidia GPUs.\n",
    "\n",
    "Known as cuBLAS, the library is a set of low-level subroutines created to run linear algebra operations as quickly as possible on the Nvidia chip hardware. Most chipmakers have their own BLAS libraries. For example, Intel's is known as the Intel Math Kernel Library, or MKL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.9 µs ± 6.54 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 t2 = m1@m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.697247706422018"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40.3/10.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70275.22935779816"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "766*1000 / 10.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough, this takes just over one fourth as long as matmul with einstein summation did.\n",
    "\n",
    "Much more extraordinarily, it is more than a whopping *70,000 times faster* than computing matrix multiplication with our initial pure Python attempt that used for-loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "\n",
    "There were some methods written in this notebook that we'll want to use in the subsequent notebooks where we'll continue to build parts of fastai/PyTorch from scratch. \n",
    "\n",
    "Running the script below will store in a separate `.py` file all the functions in all code boxes in this notebook that contain an `#export` comment.\n",
    "\n",
    "Importing this `.py` file in subsequent notebooks will allow us to access and use these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_matmul_my_reimplementation.ipynb to nb_01.py\r\n"
     ]
    }
   ],
   "source": [
    "!./notebook2script_my_reimplementation.py 01_matmul_my_reimplementation.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

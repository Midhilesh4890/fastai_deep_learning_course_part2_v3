{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batch Training from Foundations\n",
    "\n",
    "#### Last Time\n",
    "[Most recently](http://nbviewer.jupyter.org/github/jamesdellinger/fastai_deep_learning_course_part2_v3/blob/master/02_fully_connected_my_reimplementation.ipynb?flush_cache=true) we saw how to implement from scratch both the forward and backward passes of a neural network.\n",
    "\n",
    "After an extended focus on weight initialization, by which we saw how to derive the basic principals that underpin the now widely-used [Kaiming weight init](02_fully_connected_my_reimplementation.ipynb), we spent some extended time refactoring the code of our forward/backward passes. \n",
    "\n",
    "We learned that organizing this code into classes was more concise and interpretable (by human readers) than leaving the logic inside sundry, scattered methods. Finally, we wrapped things up by creating our own `Module()` class that's similar to PyTorch's `nn.Module`, and let our custom loss/linear layer/ReLU classes inherit from it.\n",
    "\n",
    "According to the rules we set for ourselves at the beginning of this course, we're free to use the PyTorch versions of all classes/functionalities we've thus far implemented from scratch.\n",
    "\n",
    "#### Minibatch Training\n",
    "Today we'll implement a model that supports another must-have feature of any deep learning model: the ability to train using mini-batches.\n",
    "\n",
    "Mini-batches allow us to update our model weights by leveraging the parallel processing capability of Nvidia GPUs to train on several inputs *at the same time*. \n",
    "\n",
    "This allows our model to complete a single pass through all the training samples in our dataset in *a much shorter amount of time* than if it were to have to train and update weights for each and every single input in the training set, one at a time!\n",
    "\n",
    "#### What Components We Implement Here\n",
    "In building up to being able to create a model that can successfully train on mini-batches, we implement from scratch several other crucial components below. These include:\n",
    "* Cross entropy loss\n",
    "* Updating and registering model parameters\n",
    "* Optimzer classes\n",
    "* Dataset and Dataloader classes\n",
    "* Random Sampling\n",
    "* Setting aside a Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exports.nb_02 import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data\n",
    "We continue to use the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset as a baseline to test the functionality and performance of all the classes we create from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = x_train.shape # 50,000 images x 784 pixels per image\n",
    "c = int(y_train.max()) + 1 # number of classes in dataset\n",
    "nh = 50 # size of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy Loss\n",
    "\n",
    "In the previous notebook we used a quick-and-dirty mean squared error loss function just so we could have a simple loss function to use to test whether our model was correctly calculating weight gradients. Now, however, it's time to implement a loss function which is better tailored to the MNIST task, which entails predicting one class (out of ten total) to which a handwriting sample of a single-digit number most likely belongs.\n",
    "\n",
    "To build cross entropy loss, we first calculate the softmax of our activations, $$\\textrm{softmax}(x)_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + ... + e^{x_{n-1}}}$$ or more concisely, $$\\textrm{softmax}(x)_{i} = \\frac{e^{x_{i}}}{\\sum_{0\\leq{j}\\leq{n-1}}e^{x_{j}}}$$\n",
    "\n",
    "Note that in practice, we need to take the lof of the softmax in order to calculate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp()/x.exp().sum(-1,keepdim=True)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred = log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the cross entropy loss between a target $x$ and a prediction $p(x)$ is $$-\\sum{x\\log{p(x)}}$$ However, since its more computationally efficient to take advantage of the fact that each $x$ is one-hot encoded, we can rewrite this as $-\\log{p_{i}}$, where $i$ is the index of the target's ground truth class.\n",
    "\n",
    "We can use [numpy-style integer array indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) to implement this. PyTorch happens to include support for everything we'll need.\n",
    "\n",
    "Here's the ground truth label of the first training sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the softmax value at the 5th index of our model's prediction for this training image, which is the index corresponds to the correct ground truth label (the number 5, out of numbers 0 through 9, inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.3330, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we'd index into our predictions to find softmax values at the appropriate indices for more than one image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3330, -2.2036, -2.2567], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0,1,2], [5,0,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've obtained the softmax log of our predictions we're ready to compute the actual cross-entropy loss. The negative log-likelihood function is how we do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3143, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed further, let's pause and remember that thanks to a property of logarithms, we can rewrite the cross entropy function in a more computationally efficient structure (we get rid of the division operation): $$\\log{\\left(\\frac{a}{b}\\right)} = \\log{\\left(a\\right)} - \\log{\\left(b\\right)}$$ \n",
    "\n",
    "Let's write a new version of `log_softmax()` that takes advantage of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ensure that this refactoring is computationally accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(nll(log_softmax(pred), y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost done, but there's one more really helpful tweak that we should build in. \n",
    "\n",
    "The [LogSumExp trick](https://en.wikipedia.org/wiki/LogSumExp) lets us use the following formula to compute the sum of exponentials in a more stable manner: $$\\log{\\left(\\sum_{j=1}^{n}e^{x_{j}}\\right)} = \\log{\\left(e^{a}\\sum_{j=1}^{n}e^{x_{j}-a}\\right)} = a + \\log{\\left(\\sum_{j=1}^{n}e^{x_{j}-a}\\right)}$$ where $a$ is the maximum of all $x_{j}$.\n",
    "\n",
    "Given that to calculate cross entropy we have to take a sum of exponential terms (as evidenced by the \n",
    "```\n",
    "x.exp().sum(-1,keepdim=True)\n",
    "``` \n",
    "portion of the above `log_softmax()` function), implementing a revised version of our `log_softmax()` function that uses this trick will ensure we avoid an overflow if we have to take the exponential of a big activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0] # take the max along the highest dimension of the tensor\n",
    "    return m + (x - m[:,None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has `logsumexp` as a built-in method so lets compare it to ours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(logsumexp(pred),   # ours\n",
    "          pred.logsumexp(-1) # PyTorch's\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our final refactored `log_softmax()` with `logsumexp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that our latest log_softmax refactoring is still correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(nll(log_softmax(pred), y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the same for PyTorch's own functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(F.cross_entropy(pred, y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch combines `F.nll_loss` and `F.log_softmax` into one optimized function called `F.cross_entropy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(F.cross_entropy(pred, y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Basic Training Loop\n",
    "\n",
    "To complete one training loop, our model must be able to perform the following:\n",
    "1. Get the output of the model on **a batch** of inputs.\n",
    "* Compare the output to the labels and compute a loss.\n",
    "* Calculate the gradients of the loss with respect to every parameter in the model.\n",
    "* Update model parameters with their gradients in order to make the parameters a little bit better.\n",
    "\n",
    "Below we implement each of these steps in successive lines of code. Further down in this notebook we will see how to refactor into specific classes that manage tasks like storing a dataset, loading the data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1903, -0.2473, -0.0709,  0.1747,  0.0623, -0.0462,  0.0193, -0.0789,\n",
       "         -0.3088,  0.0329], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64                # batch size\n",
    "    \n",
    "xb = x_train[0:bs]     # a mini-batch from inputs x \n",
    "preds = model(xb)      # predictions on items in the mini-batch\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2921, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1094)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5   # learning rate\n",
    "epochs = 1 # number of epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        loss = loss_func(model(xb), yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias  .grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2049, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating model.parameters\n",
    "In the training loop that we wrote above, layer weights and biases were manually updated and then zeroed out. Instead of this, we can write our model class in such a way, using `self.l1` and `self.l2`, such that we can update all the model's trainable parameters after each forward pass by calling `model.parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        \n",
    "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m,nh,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children(): print(f'{name}: {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1)//bs + 1):\n",
    "            start_i = i*bs\n",
    "            end_i = start_i+bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad*lr\n",
    "                model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0599, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does PyTorch know what the model's parameters are? It overrides the `__setattr__` function inside the `nn.Module` class in order to register as model parameters the weights and biases inside the submodules (`self.l`, `self.l2`) that were defined in the model's class.\n",
    "\n",
    "Here's a sample dummy module that mocks up what's going on in `nn.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModule():\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __setattr__(self,k,v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k,v)\n",
    "        \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            for p in l.parameters(): yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_mdl = DummyModule(m,nh,10)\n",
    "dummy_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([50, 784]),\n",
       " torch.Size([50]),\n",
       " torch.Size([10, 50]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.shape for o in dummy_mdl.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering Modules\n",
    "\n",
    "For deeper models, it's obviously going to be a hassle to declare a `self.<layer_name>` variable for each and every layer in the model. It's probably more convenient to just pass in a list that contains all the layers. E.g. something like\n",
    "```\n",
    "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]\n",
    "self.layers = layers\n",
    "```\n",
    "\n",
    "However in order to do this we have to manually register the modules because `nn.Module` won't automatically do so for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.ModuleList and nn.Sequential\n",
    "\n",
    "Thankfully both the `nn.ModuleList` and `nn.Sequential` classes can help us do this.\n",
    "\n",
    "`nn.Sequential` just uses an `nn.ModuleList` object to store the layers. This object automatically registers all layers.\n",
    "\n",
    "Here's a home-grown clone of `nn.Sequential` that depicts how `nn.ModuleList` is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequentialModel(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0487, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `nn.Sequential` already does all of the above on its own, we can just use it going forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2406, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1081, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoring the Optimizer\n",
    "\n",
    "In our training loops above we manually coded the optimization step\n",
    "```\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad*lr\n",
    "    model.zero_grad()\n",
    "```\n",
    "\n",
    "We can refactor this logic into our own `Optimizer` class, which can be much more concisely called from our training loop:\n",
    "```\n",
    "opt.step()\n",
    "opt.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params, self.lr = list(params), lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad*lr\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred,yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0965, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch's own `optim.SGD` class functions identically to our home-grown `Optimizer` class, with the exception that `optim.SGD` also handles momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3045, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3869, grad_fn=<NllLossBackward>), tensor(0.8750))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't be afraid to include random tests such as this one right below. Although there may well be times when accuracy would dip below `0.7` (due to randomness), having checks like this interspersed throughout your code does much more good than harm, on the whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc>0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In our early crack at coding up a training loop, we iterated through minibatches of `x` and `y` values separately:\n",
    "```\n",
    "xb = x_train[start_i:end_i]\n",
    "yb = y_train[start_i:end_i]\n",
    "```\n",
    "If, however, we create a `Dataset` class to hold our inputs and labels, we can accomplish those steps at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x, self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "assert len(train_ds)==len(x_train)\n",
    "assert len(valid_ds)==len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = train_ds[0:5]\n",
    "assert xb.shape==(5,28*28)\n",
    "assert yb.shape==(5,)\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        xb,yb = train_ds[i*bs: i*bs+bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1239, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "Our first crack at coding a training loop explicitly iterated over batches using a for-loop that kept track of specific indices. \n",
    "```\n",
    "for i in range((n-1)//bs + 1):\n",
    "    xb,yb = train_ds[i*bs: i*bs+bs]\n",
    "```\n",
    "\n",
    "Creating a `DataLoader` class will allow for a more concise implementation thanks to the inclusion of a generator that automatically yields the next batch as soon as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self,ds,bs): self.ds, self.bs = ds,bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "assert xb.shape==(bs,28*28)\n",
    "assert yb.shape==(bs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1291, grad_fn=<NllLossBackward>), tensor(0.9688))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Should be Random\n",
    "\n",
    "When training:\n",
    "* training set should be in *random* order\n",
    "* that order should differ on each iteration\n",
    "\n",
    "However for validation:\n",
    "* validation set should *never* be randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.n, self.bs, self.shuffle = len(ds), bs, shuffle\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs): yield self.idxs[i: i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ds = Dataset(*train_ds[:10])\n",
    "s = Sampler(small_ds, 3, False)\n",
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([9, 7, 3]), tensor([1, 0, 6]), tensor([2, 8, 5]), tensor([4])]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Sampler(small_ds, 3, True)\n",
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty random. Good.\n",
    "\n",
    "Let's rewrite our `DataLoader` to take advantage of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, sampler, collate_fn=collate):\n",
    "        self.ds, self.sampler, self.collate_fn = ds, sampler, collate_fn\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
    "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHMJJREFUeJzt3X/QbXVdL/D3Jw6CYvyQyZjGW4jGr1OKoIIwImB51dIw4I7NmETaaJe5huEtp7CLmTPW3PzJVRutKB0vFQ40Kal3+CEoauNhjHsSRATiWuIBjvIbE/neP/Y6eXp8nvNj732e9Zzvfr1m9qxnr7U+a33OOmue97P2Xj+qtRYAoE8/NHYDAMCuI+gBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGPrxm5gV6iqW5Psm+S2kVsBgGkdnOTe1tqTZ1lIl0GfScg/YXgBwMIa9aP7qnpSVf1ZVf1rVX2nqm6rqndW1QEzLvq2efQHACO7bdYFjHZEX1VPSXJtkicm+dskNyZ5dpLfSPLCqjqhtXb3WP0BQA/GPKJ/byYh/7rW2qmttTe21k5J8o4khyV564i9AUAXqrW2+iutOiTJ1zL5SOIprbVHt5r2w0m+kaSSPLG19sAUy9+Q5Oj5dAsAo7mutXbMLAsY64j+lGH4qa1DPklaa/cl+WySxyU5brUbA4CejPUd/WHD8KYVpn81yQuSHJrk8pUWMhy5L+fw6VsDgH6MdUS/3zC8Z4XpW8bvvwq9AEC31up19DUMt3kCwUrfW/iOHgAmxjqi33LEvt8K0/ddMh8AMIWxgv4rw/DQFab/5DBc6Tt8AGAHjBX0Vw7DF1TVf+hhuLzuhCQPJfn8ajcGAD0ZJehba19L8qlMbth/9pLJb06yT5K/nOYaegDg+8Y8Ge+/ZnIL3HdX1fOT3JDk2CQnZ/KR/e+O2BsAdGG0W+AOR/XPTHJhJgF/bpKnJHl3kue4zz0AzG7Uy+taa/8vyVlj9gAAPRv1MbUAwK4l6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADq2buwGYC046qijpq69+uqrZ1r3l7/85alrH3jggZnWfdlll01d+8d//MczrRtYHY7oAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOuYxtZDkiCOOmLr28Y9//Ezrfvaznz1T/Sye8YxnTF27YcOGmdZ91VVXzVQP7BhH9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMc+jhwW2//77T137N3/zNzOt+7nPfe5M9TfeeONM9bAoRjuir6rbqqqt8LpjrL4AoCdjH9Hfk+Sdy4y/f7UbAYAejR30326tnT9yDwDQLSfjAUDHxj6i36uqXpHkx5M8kOT6JFe31r43blsA0Iexg/6gJB9aMu7Wqjqrtfbp7RVX1YYVJh0+c2cA0IExP7r/8yTPzyTs90ny00n+JMnBSf6+qp4+XmsA0IfRjuhba29eMmpjktdW1f1Jzk1yfpKXbWcZxyw3fjjSP3oObQLAbm0tnoz3/mF44qhdAEAH1mLQbxqG+4zaBQB0YC0G/XOG4S2jdgEAHRgl6KtqfVU9YZnxP5HkguHth1e3KwDoz1gn452R5I1VdWWSW5Pcl+QpSX4uyd5JLkvyP0fqDQC6MVbQX5nksCTPyOSj+n2SfDvJZzK5rv5DrbU2Um8A0I1Rgn64Gc52b4gDq+WOO6Z/YOLDDz8807r33nvvmerHcuCBB85U/+Y3L73Cdue85S1vmbp248aNM60bdidr8WQ8AGBOBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHqrU2dg9zV1Ubkhw9dh8shiOPPHKm+j333HPq2he/+MUzrfutb33rTPVj+ou/+Iupa88666w5dgK71HWttWNmWYAjegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI55TC3sxvbYY4+Z6n/rt35r6tqxH3H7wAMPTF17yCGHzLTuO++8c6Z62AkeUwsArEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdMzz6GGBHXnkkVPXbty4cY6drK4/+qM/mqn+jW9845w6ge3yPHoAYGWCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6tm7sBgBW2/777z9TfVVNXdvjo8FZ2+ZyRF9Vp1fVe6rqmqq6t6paVX14OzXHV9VlVbW5qh6squur6pyq2mMePQEA8zuiPy/J05Pcn+TrSQ7f1sxV9QtJPprk4SR/lWRzkpckeUeSE5KcMae+AGChzes7+tcnOTTJvkl+fVszVtW+ST6Q5HtJTmqtvaq19t+THJXkc0lOr6qXz6kvAFhocwn61tqVrbWvth378un0JD+S5KLW2he3WsbDmXwykGznjwUAYMeMcdb9KcPwE8tMuzrJg0mOr6q9Vq8lAOjTGEF/2DC8aemE1tojSW7N5NyBQ1azKQDo0RiX1+03DO9ZYfqW8du9/qWqNqwwaZsnAwLAoliLN8zZcoGqi00BYEZjHNFvOWLfb4Xp+y6Zb0WttWOWGz8c6R+9860BQF/GOKL/yjA8dOmEqlqX5MlJHklyy2o2BQA9GiPorxiGL1xm2olJHpfk2tbad1avJQDo0xhBf3GSu5K8vKqeuWVkVe2d5A+Gt+8boS8A6M5cvqOvqlOTnDq8PWgYPqeqLhx+vqu19oYkaa3dW1W/lkngX1VVF2VyC9yXZnLp3cWZ3BYXAJjRvE7GOyrJmUvGHZLvXwv/z0nesGVCa+3Sqnpekt9NclqSvZPcnOQ3k7x7B++wBwBsx1yCvrV2fpLzd7Lms0lePI/1AwDLqx4Pnl1eBzvmyCOPnLp248aNc+xk97LXXtPfofu73/3uHDthAVy30qXkO2ot3jAHAJgTQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHZvL8+iB3dODDz44de23vvWtmdZ9wAEHzFRfVVPX9vh4bliJI3oA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6Jjn0TM3++yzz0z1r3jFK0apTZIbbrhh6tqPfexjM617Fv/0T/80U/3Xvva1qWs/+9nPzrTun//5n5+p3jPlYcc4ogeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOhY9fiox6rakOTosftYNE996lNnqr/pppvm1Mni2LRp00z1mzdvnrr2SU960kzrfvzjHz9TfVVNXXvhhRfOtO5f/dVfnbq2x9+57FLXtdaOmWUBjugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGPrxm6Afhx33HFjt7BwnvjEJ45aP6ZZnuu+efPm0dYNq20uR/RVdXpVvaeqrqmqe6uqVdWHV5j34GH6Sq+L5tETADC/I/rzkjw9yf1Jvp7k8B2o+cckly4zfuOcegKAhTevoH99JgF/c5LnJblyB2q+1Fo7f07rBwCWMZegb639e7BX1TwWCQDMwZgn4/1YVb0myYFJ7k7yudba9SP2AwDdGTPof3Z4/buquirJma2123dkAVW1YYVJO3KOAAB0b4zr6B9M8pYkxyQ5YHht+V7/pCSXV9U+I/QFAN1Z9SP61tqmJL+3ZPTVVfWCJJ9JcmySVyd51w4s65jlxg9H+kfP2CoA7PbWzJ3xWmuPJPng8PbEMXsBgF6smaAf3DkMfXQPAHOw1oJ+yz1Ubxm1CwDoxKoHfVUdW1WPWWb8KZnceCdJlr19LgCwc+ZyMl5VnZrk1OHtQcPwOVV14fDzXa21Nww//2GS9cOldF8fxj0tySnDz29qrV07j74AYNHN66z7o5KcuWTcIcMrSf45yZag/1CSlyV5VpIXJdkzyTeT/HWSC1pr18ypJwBYePO6Be75Sc7fwXn/NMmfzmO9AMC2eR49c/P5z39+7BZG8YUvfGGm+sMOO2zq2n32me0ClT333HOm+t3VYx7zA6cJ7ZRZnunhWfastrV21j0AMEeCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA65jG1zM0jjzwyU/1DDz00de1jH/vYmdY9i1kfFfusZz1rlNok+chHPjJ17SyPak3GfVzr2WefPVP9o48+OnXteeedN9O677vvvpnqWTyO6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgYzXmM6F3larakOTosftg57z3ve+duva1r33tHDtZXbM82/zmm2+ead2HHnroTPXsvA0bNsxU//a3v33q2o9//OMzrfvee++dqZ6pXNdaO2aWBTiiB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JjH1LJm7LffflPX/tIv/dJM6z777LOnrl2/fv1M615Ud99990z1mzZtmrr2iCOOmGndu6tLLrlkpvqzzjpr6lqPuJ2ax9QCACsT9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB3zPHpIcuCBB05de/rpp8+07gsuuGDq2j322GOmdc9i1ufJn3HGGTPVb9y4cbR1z/J/VlUzrXtMl1566dS1r3zlK2da9/333z9T/W5s/OfRV9WBVfXqqrqkqm6uqoeq6p6q+kxVvaqqll1HVR1fVZdV1eaqerCqrq+qc6pqvN9cANCZdXNYxhlJ3pfkG0muTHJ7kh9N8otJPpjkRVV1Rtvqo4Oq+oUkH03ycJK/SrI5yUuSvCPJCcMyAYAZzSPob0ry0iQfb609umVkVf1Okn9Iclomof/RYfy+ST6Q5HtJTmqtfXEY/6YkVyQ5vape3lq7aA69AcBCm/mj+9baFa21v9s65IfxdyR5//D2pK0mnZ7kR5JctCXkh/kfTnLe8PbXZ+0LANj1Z91/dxg+stW4U4bhJ5aZ/+okDyY5vqr22pWNAcAimMdH98uqqnVJtpxmuXWoHzYMb1pa01p7pKpuTbI+ySFJbtjOOjasMOnwnesWAPq0K4/o35bkp5Jc1lr75Fbj9xuG96xQt2X8/ruqMQBYFLvkiL6qXpfk3CQ3JvnlnS0fhtu9wH+lawtdRw8AE3M/oq+qs5O8K8mXk5zcWtu8ZJYtR+z7ZXn7LpkPAJjSXIO+qs5JckGSjZmE/B3LzPaVYXjoMvXrkjw5k5P3bplnbwCwiOYW9FX125nc8OZLmYT8phVmvWIYvnCZaScmeVySa1tr35lXbwCwqOYS9MPNbt6WZEOS57fW7trG7BcnuSvJy6vqmVstY+8kfzC8fd88+gKARTfzyXhVdWaS38/kTnfXJHndMg9tuK21dmGStNburapfyyTwr6qqizK5Be5LM7n07uJMbosLAMxoHmfdP3kY7pHknBXm+XSSC7e8aa1dWlXPS/K7mdwid+8kNyf5zSTvbj0+Ug8ARuAxtTCyQw45ZOran/mZn5lp3d/85jenrv3iF7+4/Zm24V/+5V9mqh/Tr/zKr0xde+6558607vXr189UP5bTTjttpvpLLrlkTp3sdsZ/TC0AsHYJegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI55Hj3AKjrooINmqr/88sunrj3iiCNmWvcsPvCBD8xU/5rXvGZOnex2PI8eAFiZoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjq0buwGARXLHHXfMVL9+/fo5dcKicEQPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB2bOeir6sCqenVVXVJVN1fVQ1V1T1V9pqpeVVU/tGT+g6uqbeN10aw9AQAT6+awjDOSvC/JN5JcmeT2JD+a5BeTfDDJi6rqjNZaW1L3j0kuXWZ5G+fQEwCQ+QT9TUlemuTjrbVHt4ysqt9J8g9JTssk9D+6pO5LrbXz57B+AGAFM39031q7orX2d1uH/DD+jiTvH96eNOt6AICdN48j+m357jB8ZJlpP1ZVr0lyYJK7k3yutXb9Lu4HABbKLgv6qlqX5JXD208sM8vPDq+ta65KcmZr7fZd1RcALJJdeUT/tiQ/leSy1tontxr/YJK3ZHIi3i3DuKclOT/JyUkur6qjWmsPbG8FVbVhhUmHT9s0APSkfvBk+DkstOp1Sd6V5MYkJ7TWNu9Azbokn0lybJJzWmvv2oGabQX943a8YwBYk65rrR0zywLmfkRfVWdnEvJfTvL8HQn5JGmtPVJVH8wk6E8clrG9mmX/8cMfAEfvcNMA0Km53hmvqs5JckEm18KfPJx5vzPuHIb7zLMvAFhUcwv6qvrtJO9I8qVMQn7TFIs5bhjess25AIAdMpegr6o3ZXLy3YZMPq6/axvzHltVj1lm/ClJXj+8/fA8+gKARTfzd/RVdWaS30/yvSTXJHldVS2d7bbW2oXDz3+YZP1wKd3Xh3FPS3LK8PObWmvXztoXADCfk/GePAz3SHLOCvN8OsmFw88fSvKyJM9K8qIkeyb5ZpK/TnJBa+2aOfQEAGQXXV43NmfdA9CJmS+v8zx6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjvUa9AeP3QAAzMHBsy5g3RyaWIvuHYa3rTD98GF4465vpRu22XRst+nYbjvPNpvOWt5uB+f7eTa1aq3N3spupqo2JElr7Zixe9ld2GbTsd2mY7vtPNtsOouw3Xr96B4AiKAHgK4JegDomKAHgI4JegDo2EKedQ8Ai8IRPQB0TNADQMcEPQB0TNADQMcEPQB0TNADQMcEPQB0bKGCvqqeVFV/VlX/WlXfqarbquqdVXXA2L2tVcM2aiu87hi7v7FU1elV9Z6quqaq7h22x4e3U3N8VV1WVZur6sGqur6qzqmqPVar77HtzHarqoO3se+1qrpotfsfQ1UdWFWvrqpLqurmqnqoqu6pqs9U1auqatnf44u+v+3sdut5f+v1efQ/oKqekuTaJE9M8reZPHv42Ul+I8kLq+qE1trdI7a4lt2T5J3LjL9/tRtZQ85L8vRMtsHX8/1nWi+rqn4hyUeTPJzkr5JsTvKSJO9IckKSM3Zls2vITm23wT8muXSZ8Rvn2NdadkaS9yX5RpIrk9ye5EeT/GKSDyZ5UVWd0ba6+5n9LckU223Q3/7WWluIV5JPJmlJ/tuS8W8fxr9/7B7X4ivJbUluG7uPtfZKcnKSn0xSSU4a9qEPrzDvvkk2JflOkmduNX7vTP74bElePva/aQ1ut4OH6ReO3ffI2+yUTEL6h5aMPyiT8GpJTttqvP1tuu3W7f62EB/dV9UhSV6QSWj9ryWT/0eSB5L8clXts8qtsZtqrV3ZWvtqG35DbMfpSX4kyUWttS9utYyHMznCTZJf3wVtrjk7ud1I0lq7orX2d621R5eMvyPJ+4e3J201yf6WqbZbtxblo/tThuGnlvlPv6+qPpvJHwLHJbl8tZvbDexVVa9I8uOZ/FF0fZKrW2vfG7et3caW/e8Ty0y7OsmDSY6vqr1aa99ZvbZ2Gz9WVa9JcmCSu5N8rrV2/cg9rRXfHYaPbDXO/rZ9y223Lbrb3xYl6A8bhjetMP2rmQT9oRH0yzkoyYeWjLu1qs5qrX16jIZ2Myvuf621R6rq1iTrkxyS5IbVbGw38bPD699V1VVJzmyt3T5KR2tAVa1L8srh7dahbn/bhm1sty26298W4qP7JPsNw3tWmL5l/P6r0Mvu5s+TPD+TsN8nyU8n+ZNMvs/6+6p6+nit7Tbsf9N5MMlbkhyT5IDh9bxMTqw6KcnlC/5129uS/FSSy1prn9xqvP1t21babt3ub4sS9NtTw9D3hku01t48fNf1zdbag621ja2112ZyEuNjk5w/boddsP8to7W2qbX2e62161pr3x5eV2fy6dsXkjw1yavH7XIcVfW6JOdmcvXQL+9s+TBcuP1tW9ut5/1tUYJ+y1+w+60wfd8l87F9W05mOXHULnYP9r85aq09ksnlUckC7n9VdXaSdyX5cpKTW2ubl8xif1vGDmy3ZfWwvy1K0H9lGB66wvSfHIYrfYfPD9o0DHfLj7JW2Yr73/B94ZMzOSnoltVsajd35zBcqP2vqs5JckEm13SfPJxBvpT9bYkd3G7bslvvb4sS9FcOwxcsczekH87kBhIPJfn8aje2G3vOMFyYXxYzuGIYvnCZaScmeVySaxf4DOhpHDcMF2b/q6rfzuSGN1/KJKw2rTCr/W0rO7HdtmW33t8WIuhba19L8qlMTiA7e8nkN2fyV9pfttYeWOXW1rSqWl9VT1hm/E9k8tdxkmzztq8kSS5OcleSl1fVM7eMrKq9k/zB8PZ9YzS2llXVsVX1mGXGn5Lk9cPbhdj/qupNmZxEtiHJ81trd21jdvvbYGe2W8/7Wy3KfSuWuQXuDUmOzeROXTclOb65Be5/UFXnJ3ljJp+I3JrkviRPSfJzmdxl67IkL2ut/dtYPY6lqk5Ncurw9qAk/zmTv/avGcbd1Vp7w5L5L87klqQXZXJL0pdmcinUxUn+yyLcRGZntttwSdP6JFdlcrvcJHlavn+d+Jtaa1uCq1tVdWaSC5N8L8l7svx367e11i7cqmbh97ed3W5d729j35pvNV9J/lMml4t9I8m/JfnnTE7OeMLYva3FVyaXlvzvTM5Q/XYmN5m4M8n/yeQ61Bq7xxG3zfmZnLW80uu2ZWpOyOSPo29l8lXR/83kSGGPsf89a3G7JXlVko9lckfL+zO5pevtmdy7/blj/1vW0DZrSa6yv8223Xre3xbmiB4AFtFCfEcPAItK0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHTs/wOlm/YeP4SpUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1800, grad_fn=<NllLossBackward>), tensor(0.9531))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()\n",
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch's DataLoader\n",
    "\n",
    "PyTorch has its own `DataLoader`, `RandomSampler` (for training), and `SequentialSampler` (for validation) classes and we can use them to create our train/valid dataloaders like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1879, grad_fn=<NllLossBackward>), tensor(0.9531))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch's defaults work fine in most cases. Note that if we pass `num_workers` to PyTorch's `DataLoader`, PyTorch will use multiple threads to call the `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1765, grad_fn=<NllLossBackward>), tensor(0.9688))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting aside a Validation Set\n",
    "\n",
    "We should **always** have a [validation set](http://www.fast.ai/2017/11/13/validation-sets/) in order to identify whether or not at some point during training our model begins to overfit.\n",
    "\n",
    "We'll write a training loop once more below, and print out the validation loss at the end of each epoch.\n",
    "\n",
    "Note that with PyTorch, you should be sure to call `model.train()` *before* training and then call `model.eval()` *before* inference. The reason is that the `nn.BatchNorm2d` and `nn.Dropout` layers' behavior is different depending on whether training or inference is being performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit (epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # Handle proper execution of bn and dropout at training.\n",
    "        for xb, yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        model.eval() # Handle proper execution of bn and dropout at inference.\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc = 0., 0.\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb)\n",
    "                tot_acc += accuracy(pred, yb)\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A question to think about: Will the validation metrics printed out here still be correct if batch size varies?\n",
    "\n",
    "And the answer is that owing to the way that the validation loss/accuracy are calculated the metrics will be incorrect if batch size varies. `tot_loss` and `tot_acc` are augmented each batch. After all batches, they are divided by the number of batches to get the average val loss/accuracy for the entire epoch.\n",
    "```\n",
    "for xb,yb in valid_dl:\n",
    "    pred = model(xb)\n",
    "    tot_loss += loss_func(pred, yb)\n",
    "    tot_acc += accuracy(pred, yb)\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "return tot_loss/nv, tot_acc/nv\n",
    "```\n",
    "If batch size varies, and say the final batch is smaller than all the others, the loss/acc of the final batch will be *over*-weighted in the epoch's loss/acc metrics.\n",
    "\n",
    "Why? Say all batches are size 64 except for the final batch, which is 16. Each batch up to the penultimate batch have an avg loss/acc (for that batch) that's divided by 64. The final batch's avg loss/acc is only divided by 16. \n",
    "\n",
    "Now, by averaging the average loss/acc of *each* of the individual batches over the total number of batches, our epoch loss/avg is essentially assuming that each each batch's avg loss/acc is calculated using the same sized denominator (batch size). In other words, `tot_loss`/`tot_acc` assumes that each pred/label pair (or each batch's average loss/acc) contributes equally to the overall epoch average loss/acc. However, we know that for the final batch, this isn't true. The denominator (batch size) is only 16 and because this isn't compensated for, the pred/label pairs in the final batch disproportionally sway the overall average epoch loss/acc.\n",
    "\n",
    "Here's a simple example to illustrate what's going on.\n",
    "\n",
    "Say we have three batches, with the first two of size 10 and the last of size 5. And if they have the following accuracies:\n",
    "$$\\frac{5}{10}, \\frac{5}{10}, \\frac{2}{5}$$ We would expect that the total combined accuracy of all samples would be: $$\\frac{5+5+2}{10+10+5} = \\frac{12}{25}$$ However, if we calculate the their combined average accuracy using the approach we used to calculate `tot_acc`, we'd calculate a combined average accuracy of $$\\frac{\\frac{5}{10} + \\frac{5}{10} + \\frac{2}{5}}{3} = \\frac{\\frac{14}{10}}{3} = \\frac{14}{30}$$ Immediately we notice that $\\frac{14}{30}$ is *less than* $\\frac{12}{25}$. \n",
    "\n",
    "In other words, the 3rd batch's lower accuracy is exerting *too large* an effect on the overall average accuracy calculation -- it is lower, just slightly, than it ought to be. The batch's accuracy of $\\frac{2}{5}$ should only contribute to $\\frac{5}{25}$ of the epoch's average accuracy (since the batch has only 5 of the 25 total samples), yet our misguided calculation has it influencing $\\frac{1}{3}$ of the epoch's average accuracy.\n",
    "\n",
    "The proper way to calculate the epoch's average accuracy that takes into account the 3rd batch's smaller size relative to the first two batches would be to calculate a weighted average: $$\\frac{5}{10}*\\frac{10}{25} + \\frac{5}{10}*\\frac{10}{25} + \\frac{2}{5}*\\frac{5}{25} = \\frac{10}{25} + \\frac{2}{25} = \\frac{12}{25}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_dls` will return dataloaders for the training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs), \n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method allows us to now create dataloaders and fit the model, in only *three lines of code*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2106) tensor(0.9356)\n",
      "1 tensor(0.3704) tensor(0.8999)\n",
      "2 tensor(0.1188) tensor(0.9648)\n",
      "3 tensor(0.1543) tensor(0.9555)\n",
      "4 tensor(0.1224) tensor(0.9647)\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "loss, acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc>0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 03_minibatch_training_my_reimplementation.ipynb to nb_03.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script_my_reimplementation.py 03_minibatch_training_my_reimplementation.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
